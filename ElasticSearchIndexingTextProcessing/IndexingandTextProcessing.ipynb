{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch5 import Elasticsearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create elasticsearch connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=\"localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Deleting the final index added for every time the program is run and index is created\n",
    "\n",
    "# es.indices.delete(index=\"shakespeare\", ignore=404)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Document mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial document mapping\n",
    "\n",
    "document_mappings = {\n",
    "    \"properties\": {\n",
    "        \"line_id\": {\"type\": \"long\"},\n",
    "        \"play_name\": {\"type\": \"text\"},\n",
    "        \"line_number\": {\"type\": \"text\"},\n",
    "        \"speaker\": {\"type\": \"text\"},\n",
    "        \"speech_number\": {\"type\": \"text\"},\n",
    "        \"speaker\": {\"type\": \"text\"},\n",
    "        \"text_entry\": {\"type\": \"text\"},\n",
    "    }\n",
    "}\n",
    "\n",
    "elastic_search_config = {\n",
    "    \"mappings\": {\n",
    "        \"line\": document_mappings,\n",
    "        \"scene\": document_mappings,\n",
    "        \"act\": document_mappings,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing the document with mapping\n",
    "\n",
    "shakespeare_index = \"shakespeare\"\n",
    "es.indices.create(index=shakespeare_index, body=elastic_search_config, ignore=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View current mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the created index's mapping\n",
    "\n",
    "mapping = es.indices.get_mapping(index=shakespeare_index)\n",
    "pprint_mapping = json.dumps(mapping, indent=4)\n",
    "print(pprint_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add document to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset file has its index as Shakespeare, three different types of fields \n",
    "and ids on its metadata and detailed information of the document is on its \n",
    "subsequent line with fields, id of the line, name of the play, speech number, \n",
    "line number of the speech, name of the speaker and speaker's text entry\n",
    "\"\"\"\n",
    "\n",
    "file = \"shakespeare.json\"\n",
    "\n",
    "# Open the file containing works of Shakespeare\n",
    "with open(file) as works_of_shakespeare:\n",
    "    current_line = 1  # Initialize the current line counter\n",
    "\n",
    "    # Iterate over each line in the file\n",
    "    for line in works_of_shakespeare:\n",
    "        # Check if the current line number is odd (line numbers start from 1)\n",
    "        if current_line % 2 > 0:\n",
    "            index_info = json.loads(line.strip())  # Parse the line as JSON and store it in index_info\n",
    "        else:\n",
    "            # Parse the line as JSON and store it in document\n",
    "            document = json.loads(line.strip())\n",
    "\n",
    "            # Extract the index, document type, and document ID from index_info\n",
    "            index = index_info[\"index\"][\"_index\"]\n",
    "            doc_type = index_info[\"index\"][\"_type\"]\n",
    "            doc_id = index_info[\"index\"][\"_id\"]\n",
    "\n",
    "            # Index the document in Elasticsearch using the extracted information\n",
    "            es.index(index=index, doc_type=doc_type, id=doc_id, body=document)\n",
    "\n",
    "        current_line += 1  # Increment the current line counter\n",
    "\n",
    "        # Check if we have processed more than 300 lines\n",
    "        if current_line > 30:\n",
    "            print(\"done\")  # Print \"done\" to indicate the process is complete\n",
    "            break  # Exit the loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index stats for the \"shakespeare_index\"\n",
    "index_stats = es.indices.stats(index=shakespeare_index)\n",
    "\n",
    "# Access the count of documents in the index\n",
    "doc_count = index_stats[\"_all\"][\"primaries\"][\"docs\"][\"count\"]\n",
    "\n",
    "# Print the count of documents\n",
    "print(doc_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and Case folding using custom analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom analyzer with tokenization and casefolding\n",
    "\n",
    "custom_analyzer = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"my_custom_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\"lowercase\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "new_document_mappings = {\n",
    "    \"properties\": {\n",
    "        \"line_id\": {\"type\": \"long\"},\n",
    "        \"play_name\": {\"type\": \"text\"},\n",
    "        \"line_number\": {\"type\": \"text\"},\n",
    "        \"speaker\": {\"type\": \"text\"},\n",
    "        \"speech_number\": {\"type\": \"text\"},\n",
    "        \"speaker\": {\"type\": \"text\"},\n",
    "        \"text_entry\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"my_custom_analyzer\"\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "elastic_search_config = {\n",
    "    \"settings\": custom_analyzer,\n",
    "    \"mappings\": {\n",
    "        \"line\": new_document_mappings,\n",
    "        \"scene\": new_document_mappings,\n",
    "        \"act\": new_document_mappings,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete old index and create new index with new configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old index\n",
    "es.indices.delete(index=shakespeare_index)\n",
    "\n",
    "# create new index\n",
    "es.indices.create(\n",
    "    index=shakespeare_index, body=elastic_search_config, ignore=400\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test analyzer with tokenizations and casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing custom analyzer with tokenization and casefolding on a random text as an example\n",
    "\n",
    "analyzer_output = es.indices.analyze(\n",
    "    index=shakespeare_index,\n",
    "    body={\n",
    "        \"text\": \"Whereas few PEOPLE set out deliBratELY to defraud in THIS waY, theRe is a RISK of unintentional PlaGiarISm.\",\n",
    "        \"analyzer\": \"standard\",\n",
    "    },\n",
    ")\n",
    "tokens = analyzer_output[\"tokens\"]\n",
    "\n",
    "t = [token[\"token\"] for token in tokens]\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming or Morphological Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create custom analyzer including stemming in existing custom analyzer of Tokenization and CaseFolding\n",
    "custom_analyzer = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"my_custom_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\"lowercase\", \"porter_stem\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# update elastic search config\n",
    "\n",
    "elastic_search_config[\"settings\"] = custom_analyzer\n",
    "\n",
    "elastic_search_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new index with stemming analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete old index\n",
    "es.indices.delete(index=shakespeare_index)\n",
    "\n",
    "\n",
    "# create new index with updated document mapping of custom analyzer\n",
    "es.indices.create(index=shakespeare_index, body=elastic_search_config, ignore=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test analyzer for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of custom analyzer with stemming, tokenization, case folding on a sentence\n",
    "\n",
    "analyzer_output = es.indices.analyze(\n",
    "    index=shakespeare_index,\n",
    "    body={\n",
    "        \"text\": \"Many of his paintings show the setting sun.\",\n",
    "        \"analyzer\": \"my_custom_analyzer\",\n",
    "    },\n",
    ")\n",
    "tokens = analyzer_output[\"tokens\"]\n",
    "t = [token[\"token\"] for token in tokens]\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding stopword removal to the existing custom analyser\n",
    "custom_analyzer = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"my_custom_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\"lowercase\", \"stop\", \"porter_stem\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# update elastic search config\n",
    "\n",
    "elastic_search_config[\"settings\"] = custom_analyzer\n",
    "\n",
    "elastic_search_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new index with stopword analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete old index\n",
    "es.indices.delete(index=shakespeare_index)\n",
    "\n",
    "#create new index with updated custom analyser of stopword\n",
    "es.indices.create(index=shakespeare_index, body=elastic_search_config, ignore=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Analyzer for stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on a sample sentence fot the filters of Tokenization, Casefolding, Stemming, Removing Stopwords\n",
    "\n",
    "analyzer_output = es.indices.analyze(\n",
    "    index=shakespeare_index,\n",
    "    body={\"text\": \"The national library has always carried huge symbolic weight as a measure of attitudes towards literature and learning 22-07-19!!@98.\", \"analyzer\": \"my_custom_analyzer\"},\n",
    ")\n",
    "tokens = analyzer_output[\"tokens\"]\n",
    "t = [token[\"token\"] for token in tokens]\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add N-Gram to custom analyzer\n",
    "\n",
    "# create custom analyzer for bigram assigning max and min values\n",
    "\n",
    "custom_analyzer = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"my_custom_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\":  [\"lowercase\", \"stop\", \"porter_stem\", \"bigram\"],\n",
    "            }\n",
    "        },\n",
    "        \"filter\": {\"bigram\": {\"type\": \"ngram\", \"min_gram\": 2, \"max_gram\": 2}},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# update elastic search config\n",
    "\n",
    "elastic_search_config[\"settings\"] = custom_analyzer\n",
    "\n",
    "elastic_search_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete old index and creating new index with ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete old index\n",
    "es.indices.delete(index=shakespeare_index)\n",
    "\n",
    "#create new index with updated settings\n",
    "es.indices.create(index=shakespeare_index, body=elastic_search_config, ignore=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test analyzer for ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on a sample sentence fot the filters of Tokenization, Casefolding, Stemming, Removing Stopwords and bigrams\n",
    "\n",
    "analyzer_output = es.indices.analyze(\n",
    "    index=shakespeare_index,\n",
    "    body={\"text\": \"The national library has always carried huge symbolic weight as a measure of attitudes towards literature and learning 22-07-19!!@98.\", \"analyzer\": \"my_custom_analyzer\"},\n",
    ")\n",
    "tokens = analyzer_output[\"tokens\"]\n",
    "t = [token[\"token\"] for token in tokens]\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding TF.IDF to the updated index with ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tfidf to mapping to text entry mapping in elasticsearch config\n",
    "\n",
    "similarity_property = {\"similarity\": \"classic\"}\n",
    "\n",
    "elastic_search_config[\"mappings\"][\"line\"][\"properties\"][\"text_entry\"].update(\n",
    "    similarity_property\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete old index\n",
    "es.indices.delete(index=shakespeare_index)\n",
    "\n",
    "#create new index with updated settings\n",
    "es.indices.create(index=shakespeare_index, body=elastic_search_config, ignore=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset file to perform search queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the \"shakespeare.json\" file for reading\n",
    "with open(\"shakespeare.json\") as works_of_shakespeare:\n",
    "    current_line = 1  # Initialize the current line counter\n",
    "\n",
    "    # Iterate over each line in the file\n",
    "    for line in works_of_shakespeare:\n",
    "\n",
    "        # Check if the current line number is odd (line numbers start from 1)\n",
    "        if current_line % 2 > 0:\n",
    "            index_info = json.loads(line.strip())  # Parse the line as JSON and store it in index_info\n",
    "        else:\n",
    "            # Parse the line as JSON and store it in document\n",
    "            document = json.loads(line.strip())\n",
    "\n",
    "            # Extract the index, document type, and document ID from index_info\n",
    "            index = index_info[\"index\"][\"_index\"]\n",
    "            doc_type = index_info[\"index\"][\"_type\"]\n",
    "            doc_id = index_info[\"index\"][\"_id\"]\n",
    "\n",
    "            # Index the document in Elasticsearch using the extracted information\n",
    "            es.index(index=index, doc_type=doc_type, id=doc_id, body=document)\n",
    "\n",
    "        current_line += 1  # Increment the current line counter\n",
    "\n",
    "        # Check if we have processed more than 1000 lines\n",
    "        if current_line > 7000:\n",
    "            print(\"done\")  # Print \"done\" to indicate the process is complete\n",
    "            break  # Exit the loop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pagination to display desired number of documents from default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pagination parameters\n",
    "pagination = {\"query\": {\"match_all\": {}}, \"from\": 12, \"size\": 5}\n",
    "\n",
    "# Perform the search using Elasticsearch with the defined pagination\n",
    "pagi = es.search(index=\"shakespeare\", body=pagination)\n",
    "\n",
    "# Retrieve the paginated results\n",
    "pagi\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search query for Full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to search for documents containing the term \"pagans\" in the \"text_entry\" field\n",
    "query = {\"query\": {\"match\": {\"text_entry\": {\"query\": \"pagans\"}}}}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "resp = es.search(index=\"shakespeare\", body=query)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search query to match exact phrases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to search for documents containing the exact phrase \"thy love\" in the \"text_entry\" field\n",
    "match_phrase = {\"query\": {\"match_phrase\": {\"text_entry\": {\"query\": \"thy love\"}}}}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "resp = es.search(index=\"shakespeare\", body=match_phrase)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search query to match phrases on multipe fields using operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to search for documents containing the phrase \"ever valiant\" in the \"speaker\" or \"text_entry\" fields\n",
    "match_phrase = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": \"ever valiant\",\n",
    "            \"operator\": \"and\",\n",
    "            \"fields\": [\"speaker\", \"text_entry\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "resp = es.search(index=\"shakespeare\", body=match_phrase)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search query to match part of phrase with multiple fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to search for documents containing the partial phrase \"hol\" in the \"speaker\" or \"text_entry\" fields\n",
    "match_part_phrase = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": \"hol\",\n",
    "            \"fields\": [\"speaker\", \"text_entry\"],\n",
    "            \"type\": \"phrase_prefix\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "resp = es.search(index=\"shakespeare\", body=match_part_phrase)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting in descinding order for field line_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to retrieve all documents and sort them in descending order based on the \"line_id\" field\n",
    "sorted_query = {\"query\": {\"match_all\": {}}, \"sort\": {\"line_id\": {\"order\": \"desc\"}}}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "resp = es.search(index=\"shakespeare\", body=sorted_query)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering part of phrase on Speaker field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query to find documents where the \"speaker\" field matches \"FALSTAFF\" and the \"text_entry\" field contains the exact term \"thy\"\n",
    "match_part_phrase_filter = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"match\": {\"speaker\": \"FALSTAFF\"}}\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\"term\": {\"text_entry\": \"thy\"}}\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform the search operation using Elasticsearch with the defined query on the \"shakespeare\" index\n",
    "respFilter = es.search(index=\"shakespeare\", body=match_part_phrase_filter)\n",
    "\n",
    "# Iterate over the search results\n",
    "for hit in respFilter[\"hits\"][\"hits\"]:\n",
    "    # Print each hit\n",
    "    print(hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
